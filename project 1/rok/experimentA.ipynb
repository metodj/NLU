{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"experimentA.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"DYOLuNB7BQf8","colab_type":"code","outputId":"04f3cdd0-b641-4903-a1fb-b730bc4d7c5f","executionInfo":{"status":"ok","timestamp":1553963024452,"user_tz":-60,"elapsed":462,"user":{"displayName":"Rok Šikonja","photoUrl":"","userId":"08390144229917873056"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["import os\n","from google.colab import drive\n","drive.mount('/content/gdrive/')\n","os.chdir(\"./gdrive/My Drive/NLU/Projects/project 1/rok/\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"],"name":"stdout"}]},{"metadata":{"id":"diHhf8RFAzya","colab_type":"code","outputId":"6e4df0ed-2d2e-48b2-d55f-5dc2336aa2bf","executionInfo":{"status":"ok","timestamp":1553963027762,"user_tz":-60,"elapsed":2016,"user":{"displayName":"Rok Šikonja","photoUrl":"","userId":"08390144229917873056"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","\n","print(\"tf_version:\\t\" + tf.__version__)\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = \"3\"\n","\n","from models import ModelA\n","\n","# DIRECTORIES\n","DATA_DIR = \"./data/\"\n","RESULTS_DIR = \"./results/\"\n","WORD_EMBEDDINGS_FILE = \"wordembeddings-dim100.word2vec\"\n","SENTENCES_TRAIN_FILE = \"sentences.train\"\n","SENTENCES_TEST_FILE = \"sentences_test.txt\"\n","SENTENCES_EVAL_FILE = \"sentences.eval\"\n","SENTENCES_CONTINUATION_FILE = \"sentences.continuation\"\n","\n","# LANGUAGE MODEL PARAMETERS\n","EMBEDDING_DIM = 100\n","STATE_DIM = 512\n","VOCABULARY_SIZE = 20000\n","SENT_DIM = 30\n","\n","# RNN PARAMETERS\n","BATCH_SIZE = 64\n","LEARNING_RATE = 0.001\n","MAX_GRAD_NORM = 5.0\n","NUM_EPOCHS = 1\n","KEEP_PROBS = 0.5"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tf_version:\t1.13.1\n"],"name":"stdout"}]},{"metadata":{"id":"m43Oi1wbAzyi","colab_type":"code","outputId":"611c4bfc-a745-42aa-c1a3-a19af7ec8034","executionInfo":{"status":"ok","timestamp":1553964388847,"user_tz":-60,"elapsed":99229,"user":{"displayName":"Rok Šikonja","photoUrl":"","userId":"08390144229917873056"}},"colab":{"base_uri":"https://localhost:8080/","height":118}},"cell_type":"code","source":["EXPERIMENT = \"A\"\n","\n","tf.reset_default_graph()\n","tf.set_random_seed(12345)\n","np.random.seed(12345)\n","\n","# Train\n","model = ModelA(vocabulary_size=VOCABULARY_SIZE, embedding_dim=EMBEDDING_DIM, state_dim=STATE_DIM, sent_dim=SENT_DIM,\n","               initializer=tf.contrib.layers.xavier_initializer(), pad_idx=180, tf_graph=None)\n","\n","saver = tf.train.Saver()\n","\n","with tf.Session() as session:\n","    session.run(tf.global_variables_initializer())\n","\n","    # TRAINING\n","    session.run(model.iterator_op, {model.sentences_file: RESULTS_DIR + \"X_train.ids\"})\n","    batch_count = 0\n","    total_batch = 500\n","    while True:\n","        try:\n","            batch_loss, batch_perplexity, _ = session.run([model.loss, model.perplexity, model.optimize_op])\n","            epoch = 1\n","            if batch_count % 100 == 0:\n","                print(\"epoch: {}/{:<6}batch: {:>5}/{:<10}loss = {:<13.2f}perp = {:<13.2f}\".format(epoch, NUM_EPOCHS,\n","                                                                                                  batch_count + 1,\n","                                                                                                  total_batch,\n","                                                                                                  batch_loss,\n","                                                                                                  batch_perplexity))\n","\n","            batch_count += 1\n","            if batch_count > total_batch:\n","                break\n","        except tf.errors.OutOfRangeError:\n","            break\n","\n","    save_path = saver.save(session, MODEL_DIR + \"/experiment\" + EXPERIMENT + \n","                           \"/experiment\" + EXPERIMENT + \".ckpt\")\n","    print(\"Model saved in path: %s\" % save_path)\n","            \n","    # EVALUATION\n","    session.run(model.iterator_op, {model.sentences_file: RESULTS_DIR + \"X_eval.ids\"})\n","    eval_perplexities = np.array([], dtype=np.float32)\n","    batch_count = 0\n","    while True:\n","        try:\n","            batch_perplexities = session.run(model.perplexities)\n","            eval_perplexities = np.append(eval_perplexities, batch_perplexities)\n","            batch_count += 1\n","        except tf.errors.OutOfRangeError:\n","            break\n","\n","with open(RESULTS_DIR + \"groupXX.perplexity\" + EXPERIMENT, \"w\") as f:\n","    for i in range(eval_perplexities.shape[0]):\n","        f.write(\"%0.3f\" % eval_perplexities[i] + \"\\n\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["epoch: 1/1     batch:     1/500       loss = 287.21       perp = 1406.07      \n","epoch: 1/1     batch:   101/500       loss = 85.02        perp = 82.61        \n","epoch: 1/1     batch:   201/500       loss = 82.52        perp = 53.76        \n","epoch: 1/1     batch:   301/500       loss = 72.43        perp = 37.39        \n","epoch: 1/1     batch:   401/500       loss = 60.28        perp = 21.85        \n","epoch: 1/1     batch:   501/500       loss = 72.70        perp = 41.78        \n"],"name":"stdout"}]}]}