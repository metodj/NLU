{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"experimentB.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"L-iRZ6izc5fo","colab_type":"code","outputId":"b05380dc-be18-42c9-c053-8dbc4063419f","executionInfo":{"status":"ok","timestamp":1553964145206,"user_tz":-60,"elapsed":380,"user":{"displayName":"Rok Šikonja","photoUrl":"","userId":"08390144229917873056"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["import os\n","from google.colab import drive\n","drive.mount('/content/gdrive/')\n","os.chdir(\"./gdrive/My Drive/NLU/Projects/project 1/rok/\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"],"name":"stdout"}]},{"metadata":{"id":"uBuCJp_cc_kB","colab_type":"code","outputId":"7efddc6f-55b9-43bc-c6d0-f91352dfbb38","executionInfo":{"status":"ok","timestamp":1553964147280,"user_tz":-60,"elapsed":1937,"user":{"displayName":"Rok Šikonja","photoUrl":"","userId":"08390144229917873056"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","import pickle\n","\n","print(\"tf_version:\\t\" + tf.__version__)\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = \"3\"\n","\n","from models import ModelB\n","from load_embedding import load_embedding\n","\n","# DIRECTORIES\n","DATA_DIR = \"./data/\"\n","RESULTS_DIR = \"./results/\"\n","WORD_EMBEDDINGS_FILE = \"wordembeddings-dim100.word2vec\"\n","SENTENCES_TRAIN_FILE = \"sentences.train\"\n","SENTENCES_TEST_FILE = \"sentences_test.txt\"\n","SENTENCES_EVAL_FILE = \"sentences.eval\"\n","SENTENCES_CONTINUATION_FILE = \"sentences.continuation\"\n","\n","# LANGUAGE MODEL PARAMETERS\n","EMBEDDING_DIM = 100\n","STATE_DIM = 512\n","VOCABULARY_SIZE = 20000\n","SENT_DIM = 30\n","\n","# RNN PARAMETERS\n","BATCH_SIZE = 64\n","LEARNING_RATE = 0.001\n","MAX_GRAD_NORM = 5.0\n","NUM_EPOCHS = 1\n","KEEP_PROBS = 0.5\n","\n","# VOCABULARY\n","with open(RESULTS_DIR + \"vocabulary.pkl\", \"rb\") as f:\n","    vocabulary, word_to_idx, idx_to_word = pickle.load(f)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tf_version:\t1.13.1\n"],"name":"stdout"}]},{"metadata":{"id":"tc3whF6wdMea","colab_type":"code","outputId":"cbdd568a-41d9-4fb0-e741-dd040a12550e","executionInfo":{"status":"ok","timestamp":1553964261657,"user_tz":-60,"elapsed":115848,"user":{"displayName":"Rok Šikonja","photoUrl":"","userId":"08390144229917873056"}},"colab":{"base_uri":"https://localhost:8080/","height":3094}},"cell_type":"code","source":["EXPERIMENT = \"B\"\n","\n","tf.reset_default_graph()\n","\n","model = ModelB(vocabulary_size=VOCABULARY_SIZE, embedding_dim=EMBEDDING_DIM, state_dim=STATE_DIM, sent_dim=SENT_DIM,\n","               initializer=tf.contrib.layers.xavier_initializer(), pad_idx=180, tf_graph=None)\n","\n","saver = tf.train.Saver()\n","\n","with tf.Session() as session:\n","    session.run(tf.global_variables_initializer())\n","\n","    # TRAINING\n","    session.run(model.iterator_op, {model.sentences_file: RESULTS_DIR + \"X_train.ids\"})\n","\n","    load_embedding(session, word_to_idx, model.embedding_weight, DATA_DIR + WORD_EMBEDDINGS_FILE, EMBEDDING_DIM,\n","                   VOCABULARY_SIZE)\n","\n","    batch_count = 0\n","    total_batch = 500\n","    while True:\n","        try:\n","            batch_loss, batch_perplexity, _ = session.run([model.loss, model.perplexity, model.optimize_op])\n","            epoch = 1\n","            if batch_count % 100 == 0:\n","                print(\"epoch: {}/{:<6}batch: {:>5}/{:<10}loss = {:<13.2f}perp = {:<13.2f}\".format(epoch, NUM_EPOCHS,\n","                                                                                                  batch_count + 1,\n","                                                                                                  total_batch,\n","                                                                                                  batch_loss,\n","                                                                                                  batch_perplexity))\n","\n","            batch_count += 1\n","            if batch_count > total_batch:\n","                break\n","        except tf.errors.OutOfRangeError:\n","            break\n","\n","    save_path = saver.save(session, MODEL_DIR + \"/experiment\" + EXPERIMENT + \n","                           \"/experiment\" + EXPERIMENT + \".ckpt\")\n","    print(\"Model saved in path: %s\" % save_path)\n","            \n","    # EVALUATION\n","    session.run(model.iterator_op, {model.sentences_file: RESULTS_DIR + \"X_eval.ids\"})\n","    eval_perplexities = np.array([], dtype=np.float32)\n","    batch_count = 0\n","    while True:\n","        try:\n","            batch_perplexities = session.run(model.perplexities)\n","            eval_perplexities = np.append(eval_perplexities, batch_perplexities)\n","            batch_count += 1\n","        except tf.errors.OutOfRangeError:\n","            break\n","\n","with open(RESULTS_DIR + \"groupXX.perplexity\" + EXPERIMENT, \"w\") as f:\n","    for i in range(eval_perplexities.shape[0]):\n","        f.write(\"%0.3f\" % eval_perplexities[i] + \"\\n\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py:358: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From /content/gdrive/My Drive/NLU/Projects/project 1/rok/models.py:169: BasicLSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Loading external embeddings from ./data/wordembeddings-dim100.word2vec\n","<bos> not in embedding file\n","<eos> not in embedding file\n","<pad> not in embedding file\n","<unk> not in embedding file\n","19996 words out of 20000 could be loaded\n","epoch: 1/1     batch:     1/500       loss = 286.99       perp = 1413.96      \n","epoch: 1/1     batch:   101/500       loss = 66.63        perp = 28.80        \n","epoch: 1/1     batch:   201/500       loss = 69.24        perp = 27.05        \n","epoch: 1/1     batch:   301/500       loss = 60.30        perp = 17.64        \n","epoch: 1/1     batch:   401/500       loss = 51.90        perp = 12.86        \n","epoch: 1/1     batch:   501/500       loss = 63.64        perp = 23.06        \n","0 (64,)\n","1 (128,)\n","2 (192,)\n","3 (256,)\n","4 (320,)\n","5 (384,)\n","6 (448,)\n","7 (512,)\n","8 (576,)\n","9 (640,)\n","10 (704,)\n","11 (768,)\n","12 (832,)\n","13 (896,)\n","14 (960,)\n","15 (1024,)\n","16 (1088,)\n","17 (1152,)\n","18 (1216,)\n","19 (1280,)\n","20 (1344,)\n","21 (1408,)\n","22 (1472,)\n","23 (1536,)\n","24 (1600,)\n","25 (1664,)\n","26 (1728,)\n","27 (1792,)\n","28 (1856,)\n","29 (1920,)\n","30 (1984,)\n","31 (2048,)\n","32 (2112,)\n","33 (2176,)\n","34 (2240,)\n","35 (2304,)\n","36 (2368,)\n","37 (2432,)\n","38 (2496,)\n","39 (2560,)\n","40 (2624,)\n","41 (2688,)\n","42 (2752,)\n","43 (2816,)\n","44 (2880,)\n","45 (2944,)\n","46 (3008,)\n","47 (3072,)\n","48 (3136,)\n","49 (3200,)\n","50 (3264,)\n","51 (3328,)\n","52 (3392,)\n","53 (3456,)\n","54 (3520,)\n","55 (3584,)\n","56 (3648,)\n","57 (3712,)\n","58 (3776,)\n","59 (3840,)\n","60 (3904,)\n","61 (3968,)\n","62 (4032,)\n","63 (4096,)\n","64 (4160,)\n","65 (4224,)\n","66 (4288,)\n","67 (4352,)\n","68 (4416,)\n","69 (4480,)\n","70 (4544,)\n","71 (4608,)\n","72 (4672,)\n","73 (4736,)\n","74 (4800,)\n","75 (4864,)\n","76 (4928,)\n","77 (4992,)\n","78 (5056,)\n","79 (5120,)\n","80 (5184,)\n","81 (5248,)\n","82 (5312,)\n","83 (5376,)\n","84 (5440,)\n","85 (5504,)\n","86 (5568,)\n","87 (5632,)\n","88 (5696,)\n","89 (5760,)\n","90 (5824,)\n","91 (5888,)\n","92 (5952,)\n","93 (6016,)\n","94 (6080,)\n","95 (6144,)\n","96 (6208,)\n","97 (6272,)\n","98 (6336,)\n","99 (6400,)\n","100 (6464,)\n","101 (6528,)\n","102 (6592,)\n","103 (6656,)\n","104 (6720,)\n","105 (6784,)\n","106 (6848,)\n","107 (6912,)\n","108 (6976,)\n","109 (7040,)\n","110 (7104,)\n","111 (7168,)\n","112 (7232,)\n","113 (7296,)\n","114 (7360,)\n","115 (7424,)\n","116 (7488,)\n","117 (7552,)\n","118 (7616,)\n","119 (7680,)\n","120 (7744,)\n","121 (7808,)\n","122 (7872,)\n","123 (7936,)\n","124 (8000,)\n","125 (8064,)\n","126 (8128,)\n","127 (8192,)\n","128 (8256,)\n","129 (8320,)\n","130 (8384,)\n","131 (8448,)\n","132 (8512,)\n","133 (8576,)\n","134 (8640,)\n","135 (8704,)\n","136 (8768,)\n","137 (8832,)\n","138 (8896,)\n","139 (8960,)\n","140 (9024,)\n","141 (9088,)\n","142 (9152,)\n","143 (9216,)\n","144 (9280,)\n","145 (9344,)\n","146 (9408,)\n","147 (9472,)\n","148 (9536,)\n","149 (9600,)\n","150 (9664,)\n","151 (9728,)\n","152 (9792,)\n","153 (9846,)\n"],"name":"stdout"}]}]}