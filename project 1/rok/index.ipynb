{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"index.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"DYOLuNB7BQf8","colab_type":"code","outputId":"604e77fa-cb42-40cb-8026-dfc22740e55d","executionInfo":{"status":"ok","timestamp":1555076144731,"user_tz":-120,"elapsed":33890,"user":{"displayName":"Rok Šikonja","photoUrl":"","userId":"08390144229917873056"}},"colab":{"base_uri":"https://localhost:8080/","height":261}},"cell_type":"code","source":["import os\n","import platform\n","import sys\n","from google.colab import drive\n","drive.mount('/content/gdrive/', force_remount=True)\n","os.chdir(\"./gdrive/My Drive/NLU/Projects/project 1/rok/\")\n","\n","import tensorflow as tf\n","import numpy as np\n","import pickle\n","import warnings\n","\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = \"3\"\n","tf.logging.set_verbosity(tf.logging.ERROR)\n","\n","from model import Model\n","from load_embedding import load_embedding\n","import utils\n","import tf_utils\n","\n","logger = utils.Logger(\"./logs/\")\n","timer = utils.Timer()\n","\n","!pip install tensorboardcolab\n","from tensorboardcolab import *\n","tbc = TensorBoardColab()\n","\n","logger.append(\"SYSTEM\", platform.system())\n","logger.append(\"MACHINE\", platform.machine())\n","logger.append(\"PLATFORM\", platform.platform())\n","logger.append(\"UNAME\", platform.uname(), \"\\n\")\n","\n","logger.append(\"PYTHON\", sys.version.split('\\n'))\n","logger.append(\"TF VERSION\", tf.__version__, \"\\n\")"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive/\n"],"name":"stdout"},{"output_type":"stream","text":["paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n"],"name":"stderr"},{"output_type":"stream","text":["Requirement already satisfied: tensorboardcolab in /usr/local/lib/python3.6/dist-packages (0.0.22)\n"],"name":"stdout"},{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Wait for 8 seconds...\n","TensorBoard link:\n","https://36867765.ngrok.io\n","SYSTEM                                  Linux          \n","MACHINE                                 x86_64         \n","PLATFORM                                Linux-4.14.79+-x86_64-with-Ubuntu-18.04-bionic\n","UNAME                                   uname_result(system='Linux', node='7be8b888bfaf', release='4.14.79+', version='#1 SMP Wed Dec 19 21:19:13 PST 2018', machine='x86_64', processor='x86_64')\n","              \n","PYTHON                                  ['3.6.7 (default, Oct 22 2018, 11:32:17) ', '[GCC 8.2.0]']\n","TF VERSION                              1.13.1         \n","              \n"],"name":"stdout"}]},{"metadata":{"id":"m43Oi1wbAzyi","colab_type":"code","outputId":"ba54df84-cc4c-464f-a270-428127ee6699","executionInfo":{"status":"ok","timestamp":1555076212692,"user_tz":-120,"elapsed":21194,"user":{"displayName":"Rok Šikonja","photoUrl":"","userId":"08390144229917873056"}},"colab":{"base_uri":"https://localhost:8080/","height":781}},"cell_type":"code","source":["# MODEL\n","tf.app.flags.DEFINE_string(\"EXPERIMENT\", \"C\", \"model selection (A, B, C)\")\n","tf.app.flags.DEFINE_string(\"MODE\", \"G\", \"mode (Experiment - E, Generation - G)\")\n","tf.app.flags.DEFINE_boolean(\"RESTORE\", True, \"mode (Experiment - E, Generation - G)\")\n","\n","# -------------------------------------------------------------------------------------------------------------------- #\n","# DIRECTORIES AND FILES\n","tf.app.flags.DEFINE_string(\"DATA_DIR\", \"./data/\", \"data directory\")\n","tf.app.flags.DEFINE_string(\"RESULTS_DIR\", \"./results/\", \"results directory\")\n","tf.app.flags.DEFINE_string(\"MODEL_DIR\", \"./model/\", \"saved model directory\")\n","tf.app.flags.DEFINE_string(\"WORD_EMBEDDINGS_FILE\", \"wordembeddings-dim100.word2vec\", \"word embedding file\")\n","tf.app.flags.DEFINE_string(\"SENTENCES_TRAIN_FILE\", \"sentences.train\", \"train file\")\n","tf.app.flags.DEFINE_string(\"SENTENCES_TEST_FILE\", \"sentences_test.txt\", \"test file\")\n","tf.app.flags.DEFINE_string(\"SENTENCES_EVAL_FILE\", \"sentences.eval\", \"evaluation file\")\n","tf.app.flags.DEFINE_string(\"SENTENCES_CONTINUATION_FILE\", \"sentences.continuation\", \"continuation file\")\n","\n","# LANGUAGE MODEL PARAMETERS\n","tf.app.flags.DEFINE_integer(\"EMBEDDING_DIM\", 100, \"word embedding dimension\")\n","tf.app.flags.DEFINE_integer(\"DOWN_STATE_DIM\", 512, \"down projection dimension\")\n","tf.app.flags.DEFINE_integer(\"STATE_DIM\", 512, \"rnn cell hidden state dimension\")\n","tf.app.flags.DEFINE_integer(\"VOCABULARY_SIZE\", 20000, \"vocabulary size\")\n","tf.app.flags.DEFINE_integer(\"SENT_DIM\", 30, \"train sentence length\")\n","tf.app.flags.DEFINE_integer(\"CONT_DIM\", 20, \"continuation max. sentence length\")\n","\n","# RNN PARAMETERS\n","tf.app.flags.DEFINE_integer(\"BATCH_SIZE\", 64, \"batch size\")\n","tf.app.flags.DEFINE_integer(\"NUM_EPOCHS\", 1, \"number of epochs for training\")\n","tf.app.flags.DEFINE_float(\"LEARNING_RATE\", 0.001, \"learning rate for rnn\")\n","tf.app.flags.DEFINE_float(\"MAX_GRAD_NORM\", 5.0, \"max. norm for gradient clipping\")\n","tf.app.flags.DEFINE_string('f', '', 'tensorflow bug')\n","\n","FLAGS = tf.app.flags.FLAGS\n","if FLAGS.EXPERIMENT == \"C\":\n","    FLAGS.STATE_DIM = 1024\n","tf_utils.print_flags(FLAGS, logger)\n","\n","# -------------------------------------------------------------------------------------------------------------------- #\n","# LOAD VOCABULARY\n","with open(FLAGS.RESULTS_DIR + \"vocabulary.pkl\", \"rb\") as f:\n","    vocabulary, word_to_idx, idx_to_word = pickle.load(f)\n","\n","logger.append(\"VOCABULARY LOADED.\\n\")\n","# -------------------------------------------------------------------------------------------------------------------- #\n","# RUN\n","tf.reset_default_graph()\n","tf.set_random_seed(12345)\n","np.random.seed(12345)\n","\n","model = Model(experiment=FLAGS.EXPERIMENT,\n","              mode=FLAGS.MODE,\n","              vocabulary_size=FLAGS.VOCABULARY_SIZE,\n","              embedding_dim=FLAGS.EMBEDDING_DIM,\n","              state_dim=FLAGS.STATE_DIM,\n","              down_state_dim=FLAGS.DOWN_STATE_DIM,\n","              sent_dim=FLAGS.SENT_DIM,\n","              cont_dim=FLAGS.CONT_DIM,\n","              initializer=tf.contrib.layers.xavier_initializer(),\n","              pad_idx=word_to_idx[\"<pad>\"],\n","              eos_idx=word_to_idx[\"<eos>\"],\n","              num_epochs=FLAGS.NUM_EPOCHS\n","              )\n","logger.append(\"TRAINABLE VARIABLES.\")\n","tf_utils.trainable_parameters(logger)\n","\n","saver = tf.train.Saver()\n","timer.__enter__()\n","\n","logger.append(\"TF SESSION STARTING.\\n\")\n","with tf.Session() as session:\n","    writer = tbc.get_deep_writers(\"./\")\n","    writer.add_graph(session.graph)\n","    \n","    if FLAGS.MODE == \"E\":\n","        logger.append(\"EXPERIMENT STARTING.\")\n","        with tf.name_scope(\"experiment\"):\n","            if not FLAGS.RESTORE:\n","                session.run(tf.global_variables_initializer())\n","\n","                # LOAD EMBEDDING\n","                if FLAGS.EXPERIMENT == \"B\":\n","                    load_embedding(session, word_to_idx, model.embedding_weight,\n","                                   FLAGS.DATA_DIR + FLAGS.WORD_EMBEDDINGS_FILE, \n","                                   FLAGS.EMBEDDING_DIM, FLAGS.VOCABULARY_SIZE)\n","            else:\n","                saver.restore(session, FLAGS.MODEL_DIR + \"/experiment\" + \n","                              FLAGS.EXPERIMENT + \"/experiment\" + \n","                              FLAGS.EXPERIMENT + \".ckpt\")\n","                logger.append(\"MDOEL RESTORED.\")\n","       \n","            # TRAINING\n","            summary_op = tf.summary.merge_all()\n","          \n","            session.run(model.iterator_op,\n","                        {model.sentences_file: FLAGS.RESULTS_DIR + \"X_train.ids\"})\n","\n","            logger.append(\"TRAINING STARTING.\")\n","            batch_count = 0\n","            while True:\n","                try:\n","                    batch_loss, batch_perplexity, _, global_step, summary = session.run([model.loss, model.perplexity, \n","                                                                   model.optimize_op, model.global_step, summary_op])\n","                    writer.add_summary(summary, global_step)\n","                    epoch = 1\n","                    if batch_count % 100 == 0:\n","                        logger.append(\"batch: {:>5}\".format(batch_count + 1), \"loss = {:<8.2f}\".format(batch_loss), \"perp = {:<8.2f}\".format(batch_perplexity))\n","                        \n","                    batch_count += 1\n","                except tf.errors.OutOfRangeError:\n","                    break\n","            \n","            logger.append(\"TRAINING FINISHED.\")\n","            writer.flush()\n","            save_path = saver.save(session, FLAGS.MODEL_DIR + \"/experiment\" + \n","                                   FLAGS.EXPERIMENT + \"/experiment\" + \n","                                   FLAGS.EXPERIMENT + \".ckpt\")\n","            logger.append(\"MODEL SAVED\", save_path)\n","\n","            # EVALUATION\n","            logger.append(\"EVALUATION STARTING.\")\n","            session.run(model.iterator_op, {model.sentences_file: FLAGS.RESULTS_DIR + \"X_test.ids\"})\n","            eval_perplexities = np.array([], dtype=np.float32)\n","            batch_count = 0\n","            while True:\n","                try:\n","                    batch_perplexities = session.run(model.perplexities)\n","                    eval_perplexities = np.append(eval_perplexities, batch_perplexities)\n","                    batch_count += 1\n","                except tf.errors.OutOfRangeError:\n","                    break\n","            logger.append(\"EVALUATION FINISHED.\")\n","\n","            with open(FLAGS.RESULTS_DIR + \"group23.perplexity\" + FLAGS.EXPERIMENT, \"w\") as f:\n","                for i in range(eval_perplexities.shape[0]):\n","                    f.write(\"%0.3f\" % eval_perplexities[i] + \"\\n\")\n","\n","            logger.append(\"EXPERIMENT FINISHED.\\n\")\n","    elif FLAGS.MODE == \"G\":\n","        logger.append(\"GENERATION STARTING.\")\n","        with tf.name_scope(\"generation\"):\n","            saver.restore(session, FLAGS.MODEL_DIR + \"/experiment\" + \n","                          FLAGS.EXPERIMENT + \"/experiment\" + \n","                          FLAGS.EXPERIMENT + \".ckpt\")\n","            logger.append(\"MODEL RESTORED.\")\n","            \n","            session.run(model.iterator_op, {model.sentences_file: FLAGS.RESULTS_DIR + \"X_cont.ids\"})\n","\n","\n","            continuation_ids = []\n","            batch_count = 0\n","            while True:\n","                try:\n","                    batch_predictions = session.run(model.predictions)\n","                    continuation_ids.append(batch_predictions)\n","                    batch_count = batch_count + 1\n","\n","                    print(batch_count, end=\"\\r\")\n","                except tf.errors.OutOfRangeError:\n","                    break\n","\n","            continuation_ids = np.concatenate(continuation_ids, axis=0)\n","            print(continuation_ids.shape)\n","\n","            with open(FLAGS.RESULTS_DIR + \"group23.continuation\", \"w\") as f:\n","                for i in range(continuation_ids.shape[0]):\n","                    try:\n","                        eos_pos = continuation_ids[i, 1:].tolist().index(int(word_to_idx[\"<eos>\"]))\n","                    except:\n","                        eos_pos = 20\n","\n","                    gen_sent = \" \".join([idx_to_word[token_id] if idx < eos_pos else \"\" for idx, token_id in\n","                                         enumerate(continuation_ids[i, 1:].tolist())])\n","                    f.write(gen_sent + \"\\n\")\n","        logger.append(\"GENERATION FINISHED.\\n\")\n","    logger.append(\"SESSION FINISHING.\\n\")\n","timer.__exit__()\n","tf_utils.delete_flags(FLAGS)\n","logger.create_log()"],"execution_count":2,"outputs":[{"output_type":"stream","text":["EXPERIMENT                              C              \n","MODE                                    G              \n","RESTORE                                 True           \n","DATA_DIR                                ./data/        \n","RESULTS_DIR                             ./results/     \n","MODEL_DIR                               ./model/       \n","WORD_EMBEDDINGS_FILE                    wordembeddings-dim100.word2vec\n","SENTENCES_TRAIN_FILE                    sentences.train\n","SENTENCES_TEST_FILE                     sentences_test.txt\n","SENTENCES_EVAL_FILE                     sentences.eval \n","SENTENCES_CONTINUATION_FILE             sentences.continuation\n","EMBEDDING_DIM                           100            \n","DOWN_STATE_DIM                          512            \n","STATE_DIM                               1024           \n","VOCABULARY_SIZE                         20000          \n","SENT_DIM                                30             \n","CONT_DIM                                20             \n","BATCH_SIZE                              64             \n","NUM_EPOCHS                              1              \n","LEARNING_RATE                           0.001          \n","MAX_GRAD_NORM                           5.0            \n","VOCABULARY LOADED.\n","                     \n","\n","WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","If you depend on functionality not listed there, please file an issue.\n","\n","TRAINABLE VARIABLES.                    \n","output_weight:0                         (512, 20000)   \n","embedding_weight:0                      (20000, 100)   \n","down_weight:0                           (1024, 512)    \n","lstm_cell/kernel:0                      (1124, 4096)   \n","lstm_cell/bias:0                        (4096,)        \n","num_parameters                          17372288       \n","TF SESSION STARTING.\n","                   \n","GENERATION STARTING.                    \n","MODEL RESTORED.                         \n","(10000, 21)\n","GENERATION FINISHED.\n","                   \n","SESSION FINISHING.\n","                     \n","Elapsed: 18.42281746864319s\n"],"name":"stdout"}]},{"metadata":{"id":"nvF-hVUs2-6q","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}