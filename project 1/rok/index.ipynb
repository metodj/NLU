{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"index.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"DYOLuNB7BQf8","colab_type":"code","outputId":"50fba3df-84e6-4320-ed2b-afeec1d937b4","executionInfo":{"status":"ok","timestamp":1554219230717,"user_tz":-120,"elapsed":3440,"user":{"displayName":"Rok Šikonja","photoUrl":"","userId":"08390144229917873056"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"cell_type":"code","source":["import os\n","from google.colab import drive\n","drive.mount('/content/gdrive/')\n","os.chdir(\"./gdrive/My Drive/NLU/Projects/project 1/rok/\")\n","\n","import tensorflow as tf\n","import numpy as np\n","import pickle\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","print(\"tf_version:\\t\" + tf.__version__)\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = \"3\"\n","\n","from model import Model\n","from load_embedding import load_embedding\n","import utils\n","\n","logger = utils.Logger(\"./logs/\")\n","timer = utils.Timer()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n","tf_version:\t1.13.1\n"],"name":"stdout"}]},{"metadata":{"id":"m43Oi1wbAzyi","colab_type":"code","outputId":"18730792-ff4b-4b86-ff9b-399a8f9d22cb","executionInfo":{"status":"ok","timestamp":1554244666321,"user_tz":-120,"elapsed":18211,"user":{"displayName":"Rok Šikonja","photoUrl":"","userId":"08390144229917873056"}},"colab":{"base_uri":"https://localhost:8080/","height":84}},"cell_type":"code","source":["# -------------------------------------------------------------------------------------------------------------------- #\n","# DIRECTORIES\n","DATA_DIR = \"./data/\"\n","RESULTS_DIR = \"./results/\"\n","MODEL_DIR = \"./model/\"\n","WORD_EMBEDDINGS_FILE = \"wordembeddings-dim100.word2vec\"\n","SENTENCES_TRAIN_FILE = \"sentences.train\"\n","SENTENCES_TEST_FILE = \"sentences_test.txt\"\n","SENTENCES_EVAL_FILE = \"sentences.eval\"\n","SENTENCES_CONTINUATION_FILE = \"sentences.continuation\"\n","\n","# LANGUAGE MODEL PARAMETERS\n","EMBEDDING_DIM = 100\n","STATE_DIM = 512\n","DOWN_STATE_DIM = 512\n","VOCABULARY_SIZE = 20000\n","SENT_DIM = 30\n","CONT_DIM = 20\n","\n","# RNN PARAMETERS\n","BATCH_SIZE = 64\n","LEARNING_RATE = 0.001\n","MAX_GRAD_NORM = 5.0\n","NUM_EPOCHS = 1\n","\n","with open(RESULTS_DIR + \"vocabulary.pkl\", \"rb\") as f:\n","    vocabulary, word_to_idx, idx_to_word = pickle.load(f)\n","\n","# -------------------------------------------------------------------------------------------------------------------- #\n","# RUN\n","tf.reset_default_graph()\n","tf.set_random_seed(12345)\n","np.random.seed(12345)\n","\n","# MODEL\n","EXPERIMENT = \"C\"\n","MODE = \"G\"\n","RESTORE = True\n","\n","if EXPERIMENT == \"C\":\n","    STATE_DIM = 1024\n","\n","model = Model(experiment=EXPERIMENT,\n","              mode=MODE,\n","              vocabulary_size=VOCABULARY_SIZE,\n","              embedding_dim=EMBEDDING_DIM,\n","              state_dim=STATE_DIM,\n","              down_state_dim=DOWN_STATE_DIM,\n","              sent_dim=SENT_DIM,\n","              cont_dim=CONT_DIM,\n","              initializer=tf.contrib.layers.xavier_initializer(),\n","              pad_idx=word_to_idx[\"<pad>\"],\n","              eos_idx=word_to_idx[\"<eos>\"],\n","              num_epochs=NUM_EPOCHS\n","              )\n","\n","saver = tf.train.Saver()\n","timer.__enter__()\n","\n","with tf.Session() as session:\n","    if MODE == \"E\":\n","        if not RESTORE:\n","            session.run(tf.global_variables_initializer())\n","\n","            # LOAD EMBEDDING\n","            if EXPERIMENT == \"B\":\n","                load_embedding(session, word_to_idx, model.embedding_weight,\n","                               DATA_DIR + WORD_EMBEDDINGS_FILE, EMBEDDING_DIM,\n","                               VOCABULARY_SIZE)\n","        else:\n","            saver.restore(session, MODEL_DIR + \"/experiment\" + EXPERIMENT +\n","                          \"/experiment\" + EXPERIMENT + \".ckpt\")\n","            print(\"Model restored.\")\n","        \n","        # TRAINING\n","        session.run(model.iterator_op,\n","                    {model.sentences_file: RESULTS_DIR + \"X_train.ids\"})\n","\n","        batch_count = 0\n","        total_batch = 60000\n","        while True:\n","            try:\n","                batch_loss, batch_perplexity, _ = session.run([model.loss, model.perplexity, model.optimize_op])\n","                epoch = 1\n","                if batch_count % 100 == 0:\n","                    print(\"epoch: {}/{:<6}batch: {:>5}/{:<10}loss = {:<13.2f}perp = {:<13.2f}\".format(epoch, NUM_EPOCHS,\n","                                                                                                      batch_count + 1,\n","                                                                                                      total_batch,\n","                                                                                                      batch_loss,\n","                                                                                                      batch_perplexity))\n","\n","                batch_count += 1\n","#                 if batch_count > total_batch:\n","#                     break\n","            except tf.errors.OutOfRangeError:\n","                break\n","\n","        save_path = saver.save(session, MODEL_DIR + \"/experiment\" + EXPERIMENT +\n","                               \"/experiment\" + EXPERIMENT + \".ckpt\")\n","        print(\"Model saved in path: %s\" % save_path)\n","\n","        # EVALUATION\n","        session.run(model.iterator_op, {model.sentences_file: RESULTS_DIR + \"X_eval.ids\"})\n","        eval_perplexities = np.array([], dtype=np.float32)\n","        batch_count = 0\n","        while True:\n","            try:\n","                batch_perplexities = session.run(model.perplexities)\n","                eval_perplexities = np.append(eval_perplexities, batch_perplexities)\n","                batch_count += 1\n","            except tf.errors.OutOfRangeError:\n","                break\n","        print(\"Evaluation finished.\")\n","\n","        with open(RESULTS_DIR + \"groupXX.perplexity\" + EXPERIMENT, \"w\") as f:\n","            for i in range(eval_perplexities.shape[0]):\n","                f.write(\"%0.3f\" % eval_perplexities[i] + \"\\n\")\n","\n","    elif MODE == \"G\":\n","        saver.restore(session, MODEL_DIR + \"/experiment\" + EXPERIMENT +\n","                      \"/experiment\" + EXPERIMENT + \".ckpt\")\n","        print(\"Model restored.\")\n","\n","        session.run(model.iterator_op, {model.sentences_file: RESULTS_DIR + \"X_cont.ids\"})\n","\n","\n","        continuation_ids = []\n","        batch_count = 0\n","        while True:\n","            try:\n","                batch_predictions = session.run(model.predictions)\n","                continuation_ids.append(batch_predictions)\n","                batch_count = batch_count + 1\n","\n","                print(batch_count, end=\"\\r\")\n","            except tf.errors.OutOfRangeError:\n","                break\n","\n","        continuation_ids = np.concatenate(continuation_ids, axis=0)\n","        print(continuation_ids.shape)\n","\n","        with open(RESULTS_DIR + \"groupXX.continuation\", \"w\") as f:\n","            for i in range(continuation_ids.shape[0]):\n","                try:\n","                    eos_pos = continuation_ids[i, 1:].tolist().index(int(word_to_idx[\"<eos>\"]))\n","                except:\n","                    eos_pos = 20\n","\n","                gen_sent = \" \".join([idx_to_word[token_id] if idx < eos_pos else \"\" for idx, token_id in\n","                                     enumerate(continuation_ids[i, 1:].tolist())])\n","                f.write(gen_sent + \"\\n\")\n","                \n","timer.__exit__()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from ./model//experimentC/experimentC.ckpt\n","Model restored.\n","(10000, 21)\n","Elapsed: 17.0077223777771s\n"],"name":"stdout"}]},{"metadata":{"id":"fyhTW2UrOeHC","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}