{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"experimentC.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"L-iRZ6izc5fo","colab_type":"code","outputId":"d4651049-9ab9-4ce3-ec32-fc08c3878e7f","executionInfo":{"status":"ok","timestamp":1553967978002,"user_tz":-60,"elapsed":556,"user":{"displayName":"Rok Šikonja","photoUrl":"","userId":"08390144229917873056"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["import os\n","from google.colab import drive\n","drive.mount('/content/gdrive/')\n","# os.chdir(\"./gdrive/My Drive/NLU/Projects/project 1/rok/\")"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"],"name":"stdout"}]},{"metadata":{"id":"uBuCJp_cc_kB","colab_type":"code","outputId":"901a58bd-56aa-4688-d68b-db90b50e4ff2","executionInfo":{"status":"ok","timestamp":1553968715532,"user_tz":-60,"elapsed":623,"user":{"displayName":"Rok Šikonja","photoUrl":"","userId":"08390144229917873056"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","import pickle\n","\n","print(\"tf_version:\\t\" + tf.__version__)\n","os.environ['TF_CPP_MIN_LOG_LEVEL'] = \"3\"\n","\n","from models import ModelC\n","\n","# DIRECTORIES\n","DATA_DIR = \"./data/\"\n","RESULTS_DIR = \"./results/\"\n","WORD_EMBEDDINGS_FILE = \"wordembeddings-dim100.word2vec\"\n","SENTENCES_TRAIN_FILE = \"sentences.train\"\n","SENTENCES_TEST_FILE = \"sentences_test.txt\"\n","SENTENCES_EVAL_FILE = \"sentences.eval\"\n","SENTENCES_CONTINUATION_FILE = \"sentences.continuation\"\n","MODEL_DIR = \"./model/\"\n","\n","# LANGUAGE MODEL PARAMETERS\n","EMBEDDING_DIM = 100\n","DOWN_STATE_DIM = 512\n","STATE_DIM = 1024\n","VOCABULARY_SIZE = 20000\n","SENT_DIM = 30\n","\n","# RNN PARAMETERS\n","BATCH_SIZE = 64\n","LEARNING_RATE = 0.001\n","MAX_GRAD_NORM = 5.0\n","NUM_EPOCHS = 1\n","KEEP_PROBS = 0.5"],"execution_count":13,"outputs":[{"output_type":"stream","text":["tf_version:\t1.13.1\n"],"name":"stdout"}]},{"metadata":{"id":"tc3whF6wdMea","colab_type":"code","outputId":"51bb8b19-6945-4dc0-d389-a7670a5f847e","executionInfo":{"status":"ok","timestamp":1553968802019,"user_tz":-60,"elapsed":84343,"user":{"displayName":"Rok Šikonja","photoUrl":"","userId":"08390144229917873056"}},"colab":{"base_uri":"https://localhost:8080/","height":102}},"cell_type":"code","source":["EXPERIMENT = \"C\"\n","\n","tf.reset_default_graph()\n","\n","model = ModelC(vocabulary_size=VOCABULARY_SIZE, embedding_dim=EMBEDDING_DIM, \n","               state_dim=STATE_DIM, down_state_dim=DOWN_STATE_DIM, sent_dim=SENT_DIM,\n","               initializer=tf.contrib.layers.xavier_initializer(), pad_idx=180, tf_graph=None)\n","\n","saver = tf.train.Saver()\n","\n","with tf.Session() as session:\n","    session.run(tf.global_variables_initializer())\n","\n","    # TRAINING\n","    session.run(model.iterator_op, {model.sentences_file: RESULTS_DIR + \"X_train.ids\"})\n","\n","    batch_count = 0\n","    total_batch = 300\n","    while True:\n","        try:\n","            batch_loss, batch_perplexity, _ = session.run([model.loss, model.perplexity, model.optimize_op])\n","            epoch = 1\n","            if batch_count % 100 == 0:\n","                print(\"epoch: {}/{:<6}batch: {:>5}/{:<10}loss = {:<13.2f}perp = {:<13.2f}\".format(epoch, NUM_EPOCHS,\n","                                                                                                  batch_count + 1,\n","                                                                                                  total_batch,\n","                                                                                                  batch_loss,\n","                                                                                                  batch_perplexity))\n","\n","            batch_count += 1\n","            if batch_count > total_batch:\n","                break\n","        except tf.errors.OutOfRangeError:\n","            break\n","\n","    save_path = saver.save(session, MODEL_DIR + \"/experiment\" + EXPERIMENT + \n","                           \"/experiment\" + EXPERIMENT + \".ckpt\")\n","    print(\"Model saved in path: %s\" % save_path)\n","            \n","    # EVALUATION\n","    session.run(model.iterator_op, {model.sentences_file: RESULTS_DIR + \"X_eval.ids\"})\n","    eval_perplexities = np.array([], dtype=np.float32)\n","    batch_count = 0\n","    while True:\n","        try:\n","            batch_perplexities = session.run(model.perplexities)\n","            eval_perplexities = np.append(eval_perplexities, batch_perplexities)\n","            batch_count += 1\n","        except tf.errors.OutOfRangeError:\n","            break\n","\n","with open(RESULTS_DIR + \"groupXX.perplexity\" + EXPERIMENT, \"w\") as f:\n","    for i in range(eval_perplexities.shape[0]):\n","        f.write(\"%0.3f\" % eval_perplexities[i] + \"\\n\")"],"execution_count":14,"outputs":[{"output_type":"stream","text":["epoch: 1/1     batch:     1/300       loss = 287.19       perp = 19999.98     \n","epoch: 1/1     batch:   101/300       loss = 78.26        perp = 242.99       \n","epoch: 1/1     batch:   201/300       loss = 79.88        perp = 186.34       \n","epoch: 1/1     batch:   301/300       loss = 68.79        perp = 119.94       \n","Model saved in path: ./model//experimentC/experimentC.ckpt\n"],"name":"stdout"}]},{"metadata":{"id":"6rOERUtjkfgO","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}