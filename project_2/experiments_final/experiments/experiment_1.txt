

DETAILS: 

Batch size : 8
Num epochs sentiment model training : 3
Num epochs story cloze fine tuning training : 1
Percentage training sentiment model: 0.8
Percentage training story cloze: 0.8


START TRAINING SENTIMENT PART EPOCH 1

Processed batches: 300
Batch loss: -0.92277926
Global step: 300
Processed batches: 600
Batch loss: -0.91277677
Global step: 600
Processed batches: 900
Batch loss: -0.97167754
Global step: 900
Processed batches: 1200
Batch loss: -0.9647304
Global step: 1200
Processed batches: 1500
Batch loss: -0.9358133
Global step: 1500
Processed batches: 1800
Batch loss: -0.9362567
Global step: 1800
Processed batches: 2100
Batch loss: -0.8970988
Global step: 2100
Processed batches: 2400
Batch loss: -0.911854
Global step: 2400
Processed batches: 2700
Batch loss: -0.9244673
Global step: 2700
Processed batches: 3000
Batch loss: -0.9558793
Global step: 3000
Processed batches: 3300
Batch loss: -0.95263934
Global step: 3300
Processed batches: 3600
Batch loss: -0.9463838
Global step: 3600
Processed batches: 3900
Batch loss: -0.91966677
Global step: 3900
Processed batches: 4200
Batch loss: -0.9413281
Global step: 4200
Processed batches: 4500
Batch loss: -0.90945363
Global step: 4500
Processed batches: 4800
Batch loss: -0.9493762
Global step: 4800
Processed batches: 5100
Batch loss: -0.87793577
Global step: 5100
Processed batches: 5400
Batch loss: -0.9317411
Global step: 5400
Processed batches: 5700
Batch loss: -0.9560506
Global step: 5700
Processed batches: 6000
Batch loss: -0.9523674
Global step: 6000
Processed batches: 6300
Batch loss: -0.96264935
Global step: 6300
Processed batches: 6600
Batch loss: -0.9135144
Global step: 6600
Processed batches: 6900
Batch loss: -0.9170042
Global step: 6900
Processed batches: 7200
Batch loss: -0.9170594
Global step: 7200
Processed batches: 7500
Batch loss: -0.9281641
Global step: 7500
Processed batches: 7800
Batch loss: -0.94080496
Global step: 7800
Processed batches: 8100
Batch loss: -0.9627683
Global step: 8100
Processed batches: 8400
Batch loss: -0.94244504
Global step: 8400
Processed batches: 8700
Batch loss: -0.9291326
Global step: 8700


START TESTING SENTIMENT PART EPOCH 1

Processed batches: 184
Batch loss: [-0.9604198]
Global step: 8816
Processed batches: 484
Batch loss: [-0.97450453]
Global step: 8816
Processed batches: 784
Batch loss: [-0.9190277]
Global step: 8816
Processed batches: 1084
Batch loss: [-0.89231074]
Global step: 8816
Processed batches: 1384
Batch loss: [-0.91927326]
Global step: 8816
Processed batches: 1684
Batch loss: [-0.9457282]
Global step: 8816
Processed batches: 1984
Batch loss: [-0.9150548]
Global step: 8816


START TRAINING SENTIMENT PART EPOCH 2

Processed batches: 300
Batch loss: -0.9244498
Global step: 9116
Processed batches: 600
Batch loss: -0.9161658
Global step: 9416
Processed batches: 900
Batch loss: -0.97222143
Global step: 9716
Processed batches: 1200
Batch loss: -0.96491265
Global step: 10016
Processed batches: 1500
Batch loss: -0.9358823
Global step: 10316
Processed batches: 1800
Batch loss: -0.9392283
Global step: 10616
Processed batches: 2100
Batch loss: -0.90258175
Global step: 10916
Processed batches: 2400
Batch loss: -0.9196023
Global step: 11216
Processed batches: 2700
Batch loss: -0.9230677
Global step: 11516
Processed batches: 3000
Batch loss: -0.9556656
Global step: 11816
Processed batches: 3300
Batch loss: -0.9520899
Global step: 12116
Processed batches: 3600
Batch loss: -0.9462438
Global step: 12416
Processed batches: 3900
Batch loss: -0.9196649
Global step: 12716
Processed batches: 4200
Batch loss: -0.94163954
Global step: 13016
Processed batches: 4500
Batch loss: -0.9091975
Global step: 13316
Processed batches: 4800
Batch loss: -0.951398
Global step: 13616
Processed batches: 5100
Batch loss: -0.8776281
Global step: 13916
Processed batches: 5400
Batch loss: -0.93259454
Global step: 14216
Processed batches: 5700
Batch loss: -0.95490456
Global step: 14516
Processed batches: 6000
Batch loss: -0.95262563
Global step: 14816
Processed batches: 6300
Batch loss: -0.9621161
Global step: 15116
Processed batches: 6600
Batch loss: -0.9124729
Global step: 15416
Processed batches: 6900
Batch loss: -0.9158256
Global step: 15716
Processed batches: 7200
Batch loss: -0.9172207
Global step: 16016
Processed batches: 7500
Batch loss: -0.9281305
Global step: 16316
Processed batches: 7800
Batch loss: -0.94064105
Global step: 16616
Processed batches: 8100
Batch loss: -0.9629846
Global step: 16916
Processed batches: 8400
Batch loss: -0.9423482
Global step: 17216
Processed batches: 8700
Batch loss: -0.9287553
Global step: 17516


START TESTING SENTIMENT PART EPOCH 2

Processed batches: 184
Batch loss: [-0.96059334]
Global step: 17632
Processed batches: 484
Batch loss: [-0.9742913]
Global step: 17632
Processed batches: 784
Batch loss: [-0.9189298]
Global step: 17632
Processed batches: 1084
Batch loss: [-0.8921858]
Global step: 17632
Processed batches: 1384
Batch loss: [-0.91918373]
Global step: 17632
Processed batches: 1684
Batch loss: [-0.9459189]
Global step: 17632
Processed batches: 1984
Batch loss: [-0.9148897]
Global step: 17632


START TRAINING SENTIMENT PART EPOCH 3

Processed batches: 300
Batch loss: -0.9242436
Global step: 17932
Processed batches: 600
Batch loss: -0.9168334
Global step: 18232
Processed batches: 900
Batch loss: -0.9712695
Global step: 18532
Processed batches: 1200
Batch loss: -0.96503305
Global step: 18832
Processed batches: 1500
Batch loss: -0.93523335
Global step: 19132
Processed batches: 1800
Batch loss: -0.9398868
Global step: 19432
Processed batches: 2100
Batch loss: -0.9038961
Global step: 19732
Processed batches: 2400
Batch loss: -0.92348707
Global step: 20032
Processed batches: 2700
Batch loss: -0.9233718
Global step: 20332
Processed batches: 3000
Batch loss: -0.9557433
Global step: 20632
Processed batches: 3300
Batch loss: -0.9521955
Global step: 20932
Processed batches: 3600
Batch loss: -0.9462646
Global step: 21232
Processed batches: 3900
Batch loss: -0.9203063
Global step: 21532
Processed batches: 4200
Batch loss: -0.94159436
Global step: 21832
Processed batches: 4500
Batch loss: -0.90873086
Global step: 22132
Processed batches: 4800
Batch loss: -0.9526619
Global step: 22432
Processed batches: 5100
Batch loss: -0.8773391
Global step: 22732
Processed batches: 5400
Batch loss: -0.9326807
Global step: 23032
Processed batches: 5700
Batch loss: -0.95393264
Global step: 23332
Processed batches: 6000
Batch loss: -0.95393497
Global step: 23632
Processed batches: 6300
Batch loss: -0.96173835
Global step: 23932
Processed batches: 6600
Batch loss: -0.91194606
Global step: 24232
Processed batches: 6900
Batch loss: -0.9152254
Global step: 24532
Processed batches: 7200
Batch loss: -0.91717076
Global step: 24832
Processed batches: 7500
Batch loss: -0.9286317
Global step: 25132
Processed batches: 7800
Batch loss: -0.9408143
Global step: 25432
Processed batches: 8100
Batch loss: -0.96288496
Global step: 25732
Processed batches: 8400
Batch loss: -0.941751
Global step: 26032
Processed batches: 8700
Batch loss: -0.9286504
Global step: 26332


START TESTING SENTIMENT PART EPOCH 3

Processed batches: 184
Batch loss: [-0.9606381]
Global step: 26448
Processed batches: 484
Batch loss: [-0.97439706]
Global step: 26448
Processed batches: 784
Batch loss: [-0.91844296]
Global step: 26448
Processed batches: 1084
Batch loss: [-0.8923376]
Global step: 26448
Processed batches: 1384
Batch loss: [-0.9191211]
Global step: 26448
Processed batches: 1684
Batch loss: [-0.94569874]
Global step: 26448
Processed batches: 1984
Batch loss: [-0.91551524]
Global step: 26448


STARTING TRAINING PART STORY CLOZE EPOCH 1

Processed batches: 1
Batch loss: 0.6648866
Global step: 26449
Processed batches: 2
Batch loss: 0.6723558
Global step: 26450
Processed batches: 3
Batch loss: 0.69829124
Global step: 26451
Processed batches: 4
Batch loss: 0.7036975
Global step: 26452
Processed batches: 5
Batch loss: 0.6452669
Global step: 26453
Processed batches: 6
Batch loss: 0.65243506
Global step: 26454
Processed batches: 7
Batch loss: 0.682538
Global step: 26455
Processed batches: 8
Batch loss: 0.68538934
Global step: 26456
Processed batches: 9
Batch loss: 0.69673514
Global step: 26457
Processed batches: 11
Batch loss: 0.71864194
Global step: 26459
Processed batches: 12
Batch loss: 0.68580306
Global step: 26460
Processed batches: 13
Batch loss: 0.6737321
Global step: 26461
Processed batches: 14
Batch loss: 0.65580034
Global step: 26462
Processed batches: 15
Batch loss: 0.6267376
Global step: 26463
Processed batches: 16
Batch loss: 0.66694915
Global step: 26464
Processed batches: 17
Batch loss: 0.69749373
Global step: 26465
Processed batches: 18
Batch loss: 0.68953085
Global step: 26466
Processed batches: 19
Batch loss: 0.67329174
Global step: 26467
Processed batches: 21
Batch loss: 0.6446742
Global step: 26469
Processed batches: 22
Batch loss: 0.68789655
Global step: 26470
Processed batches: 23
Batch loss: 0.6763922
Global step: 26471
Processed batches: 24
Batch loss: 0.6768595
Global step: 26472
Processed batches: 25
Batch loss: 0.63870144
Global step: 26473
Processed batches: 26
Batch loss: 0.72425056
Global step: 26474
Processed batches: 27
Batch loss: 0.75090075
Global step: 26475
Processed batches: 28
Batch loss: 0.687094
Global step: 26476
Processed batches: 29
Batch loss: 0.691328
Global step: 26477
Processed batches: 31
Batch loss: 0.6722863
Global step: 26479
Processed batches: 32
Batch loss: 0.7483705
Global step: 26480
Processed batches: 33
Batch loss: 0.65154076
Global step: 26481
Processed batches: 34
Batch loss: 0.65595114
Global step: 26482
Processed batches: 35
Batch loss: 0.65605783
Global step: 26483
Processed batches: 36
Batch loss: 0.65584195
Global step: 26484
Processed batches: 37
Batch loss: 0.6787553
Global step: 26485
Processed batches: 38
Batch loss: 0.6867569
Global step: 26486
Processed batches: 39
Batch loss: 0.71297145
Global step: 26487
Processed batches: 41
Batch loss: 0.67837185
Global step: 26489
Processed batches: 42
Batch loss: 0.68059194
Global step: 26490
Processed batches: 43
Batch loss: 0.64993083
Global step: 26491
Processed batches: 44
Batch loss: 0.70926774
Global step: 26492
Processed batches: 45
Batch loss: 0.6697916
Global step: 26493
Processed batches: 46
Batch loss: 0.6572709
Global step: 26494
Processed batches: 47
Batch loss: 0.6956454
Global step: 26495
Processed batches: 48
Batch loss: 0.6554311
Global step: 26496
Processed batches: 49
Batch loss: 0.68794614
Global step: 26497
Processed batches: 51
Batch loss: 0.6663034
Global step: 26499
Processed batches: 52
Batch loss: 0.6512586
Global step: 26500
Processed batches: 53
Batch loss: 0.66591114
Global step: 26501
Processed batches: 54
Batch loss: 0.65701246
Global step: 26502
Processed batches: 55
Batch loss: 0.6652502
Global step: 26503
Processed batches: 56
Batch loss: 0.68079144
Global step: 26504
Processed batches: 57
Batch loss: 0.71463484
Global step: 26505
Processed batches: 58
Batch loss: 0.689409
Global step: 26506
Processed batches: 59
Batch loss: 0.7122267
Global step: 26507
Processed batches: 61
Batch loss: 0.6265041
Global step: 26509
Processed batches: 62
Batch loss: 0.67395246
Global step: 26510
Processed batches: 63
Batch loss: 0.7884445
Global step: 26511
Processed batches: 64
Batch loss: 0.7658855
Global step: 26512
Processed batches: 65
Batch loss: 0.6630722
Global step: 26513
Processed batches: 66
Batch loss: 0.6997013
Global step: 26514
Processed batches: 67
Batch loss: 0.6656017
Global step: 26515
Processed batches: 68
Batch loss: 0.68767
Global step: 26516
Processed batches: 69
Batch loss: 0.77044004
Global step: 26517
Processed batches: 71
Batch loss: 0.7117501
Global step: 26519
Processed batches: 72
Batch loss: 0.7215492
Global step: 26520
Processed batches: 73
Batch loss: 0.7533642
Global step: 26521
Processed batches: 74
Batch loss: 0.6653469
Global step: 26522
Processed batches: 75
Batch loss: 0.6786008
Global step: 26523
Processed batches: 76
Batch loss: 0.6803278
Global step: 26524
Processed batches: 77
Batch loss: 0.72755677
Global step: 26525
Processed batches: 78
Batch loss: 0.7539315
Global step: 26526
Processed batches: 79
Batch loss: 0.68394935
Global step: 26527
Processed batches: 81
Batch loss: 0.64942425
Global step: 26529
Processed batches: 82
Batch loss: 0.6391978
Global step: 26530
Processed batches: 83
Batch loss: 0.63275504
Global step: 26531
Processed batches: 84
Batch loss: 0.64746004
Global step: 26532
Processed batches: 85
Batch loss: 0.6597768
Global step: 26533
Processed batches: 86
Batch loss: 0.6590445
Global step: 26534
Processed batches: 87
Batch loss: 0.623788
Global step: 26535
Processed batches: 88
Batch loss: 0.66834027
Global step: 26536
Processed batches: 89
Batch loss: 0.70150393
Global step: 26537
Processed batches: 91
Batch loss: 0.6534222
Global step: 26539
Processed batches: 92
Batch loss: 0.70055664
Global step: 26540
Processed batches: 93
Batch loss: 0.693066
Global step: 26541
Processed batches: 94
Batch loss: 0.68156046
Global step: 26542
Processed batches: 95
Batch loss: 0.66416776
Global step: 26543
Processed batches: 96
Batch loss: 0.67478323
Global step: 26544
Processed batches: 97
Batch loss: 0.7249585
Global step: 26545
Processed batches: 98
Batch loss: 0.76040447
Global step: 26546
Processed batches: 99
Batch loss: 0.66270214
Global step: 26547
Processed batches: 101
Batch loss: 0.6415026
Global step: 26549
Processed batches: 102
Batch loss: 0.7046302
Global step: 26550
Processed batches: 103
Batch loss: 0.6856898
Global step: 26551
Processed batches: 104
Batch loss: 0.65312105
Global step: 26552
Processed batches: 105
Batch loss: 0.66282403
Global step: 26553
Processed batches: 106
Batch loss: 0.6565598
Global step: 26554
Processed batches: 107
Batch loss: 0.72013855
Global step: 26555
Processed batches: 108
Batch loss: 0.6557114
Global step: 26556
Processed batches: 109
Batch loss: 0.6400471
Global step: 26557
Processed batches: 111
Batch loss: 0.6995398
Global step: 26559
Processed batches: 112
Batch loss: 0.64597046
Global step: 26560
Processed batches: 113
Batch loss: 0.70906615
Global step: 26561
Processed batches: 114
Batch loss: 0.6350136
Global step: 26562
Processed batches: 115
Batch loss: 0.73466265
Global step: 26563
Processed batches: 116
Batch loss: 0.66420966
Global step: 26564
Processed batches: 117
Batch loss: 0.67751753
Global step: 26565
Processed batches: 118
Batch loss: 0.70395076
Global step: 26566
Processed batches: 119
Batch loss: 0.7153018
Global step: 26567
Processed batches: 121
Batch loss: 0.7041323
Global step: 26569
Processed batches: 122
Batch loss: 0.6138545
Global step: 26570
Processed batches: 123
Batch loss: 0.6900961
Global step: 26571
Processed batches: 124
Batch loss: 0.6588899
Global step: 26572
Processed batches: 125
Batch loss: 0.67763263
Global step: 26573
Processed batches: 126
Batch loss: 0.61131334
Global step: 26574
Processed batches: 127
Batch loss: 0.6166949
Global step: 26575
Processed batches: 128
Batch loss: 0.723522
Global step: 26576
Processed batches: 129
Batch loss: 0.59128094
Global step: 26577
Processed batches: 131
Batch loss: 0.7340071
Global step: 26579
Processed batches: 132
Batch loss: 0.7360526
Global step: 26580
Processed batches: 133
Batch loss: 0.67348105
Global step: 26581
Processed batches: 134
Batch loss: 0.6897496
Global step: 26582
Processed batches: 135
Batch loss: 0.72234046
Global step: 26583
Processed batches: 136
Batch loss: 0.6232853
Global step: 26584
Processed batches: 137
Batch loss: 0.68646824
Global step: 26585
Processed batches: 138
Batch loss: 0.6502334
Global step: 26586
Processed batches: 139
Batch loss: 0.6504752
Global step: 26587
Processed batches: 141
Batch loss: 0.6977358
Global step: 26589
Processed batches: 142
Batch loss: 0.5962099
Global step: 26590
Processed batches: 143
Batch loss: 0.6718116
Global step: 26591
Processed batches: 144
Batch loss: 0.66164786
Global step: 26592
Processed batches: 145
Batch loss: 0.782851
Global step: 26593
Processed batches: 146
Batch loss: 0.6312885
Global step: 26594
Processed batches: 147
Batch loss: 0.6363894
Global step: 26595
Processed batches: 148
Batch loss: 0.6319089
Global step: 26596
Processed batches: 149
Batch loss: 0.7473178
Global step: 26597
Processed batches: 151
Batch loss: 0.6111202
Global step: 26599
Processed batches: 152
Batch loss: 0.69457823
Global step: 26600
Processed batches: 153
Batch loss: 0.63826424
Global step: 26601
Processed batches: 154
Batch loss: 0.61838305
Global step: 26602
Processed batches: 155
Batch loss: 0.73112696
Global step: 26603
Processed batches: 156
Batch loss: 0.6473659
Global step: 26604
Processed batches: 157
Batch loss: 0.84764993
Global step: 26605
Processed batches: 158
Batch loss: 0.68400526
Global step: 26606
Processed batches: 159
Batch loss: 0.59010065
Global step: 26607
Processed batches: 161
Batch loss: 0.6323426
Global step: 26609
Processed batches: 162
Batch loss: 0.6365628
Global step: 26610
Processed batches: 163
Batch loss: 0.69722706
Global step: 26611
Processed batches: 164
Batch loss: 0.66075015
Global step: 26612
Processed batches: 165
Batch loss: 0.62105656
Global step: 26613
Processed batches: 166
Batch loss: 0.59544206
Global step: 26614
Processed batches: 167
Batch loss: 0.63891876
Global step: 26615
Processed batches: 168
Batch loss: 0.6589711
Global step: 26616
Processed batches: 169
Batch loss: 0.6555162
Global step: 26617
Processed batches: 171
Batch loss: 0.70294523
Global step: 26619
Processed batches: 172
Batch loss: 0.7707237
Global step: 26620
Processed batches: 173
Batch loss: 0.70857537
Global step: 26621
Processed batches: 174
Batch loss: 0.6698781
Global step: 26622
Processed batches: 175
Batch loss: 0.64642674
Global step: 26623
Processed batches: 176
Batch loss: 0.7121875
Global step: 26624
Processed batches: 177
Batch loss: 0.6231219
Global step: 26625
Processed batches: 178
Batch loss: 0.6819545
Global step: 26626
Processed batches: 179
Batch loss: 0.64542854
Global step: 26627
Processed batches: 181
Batch loss: 0.61962813
Global step: 26629
Processed batches: 182
Batch loss: 0.7622811
Global step: 26630
Processed batches: 183
Batch loss: 0.7360848
Global step: 26631
Processed batches: 184
Batch loss: 0.67819256
Global step: 26632
Processed batches: 185
Batch loss: 0.6543758
Global step: 26633
Processed batches: 186
Batch loss: 0.65664744
Global step: 26634
Processed batches: 187
Batch loss: 0.5684234
Global step: 26635


STARTING TESTING PART STORY CLOZE EPOCH 1

Processed batches :1
Accuracy: 0.0
Processed batches :2
Accuracy: 0.375
Processed batches :3
Accuracy: 0.5625
Processed batches :4
Accuracy: 0.5416667
Processed batches :5
Accuracy: 0.5625
Processed batches :6
Accuracy: 0.525
Processed batches :7
Accuracy: 0.5208333
Processed batches :8
Accuracy: 0.51785713
Processed batches :9
Accuracy: 0.5
Processed batches :10
Accuracy: 0.5
Processed batches :11
Accuracy: 0.5125
Processed batches :12
Accuracy: 0.5
Processed batches :13
Accuracy: 0.48958334
Processed batches :14
Accuracy: 0.4903846
Processed batches :15
Accuracy: 0.5
Processed batches :16
Accuracy: 0.5083333
Processed batches :17
Accuracy: 0.5234375
Processed batches :18
Accuracy: 0.52205884
Processed batches :19
Accuracy: 0.5208333
Processed batches :20
Accuracy: 0.53289473
Processed batches :21
Accuracy: 0.525
Processed batches :22
Accuracy: 0.51785713
Processed batches :23
Accuracy: 0.51704544
Processed batches :24
Accuracy: 0.52717394
Processed batches :25
Accuracy: 0.5260417
Processed batches :26
Accuracy: 0.53
Processed batches :27
Accuracy: 0.53365386
Processed batches :28
Accuracy: 0.5416667
Processed batches :29
Accuracy: 0.53571427
Processed batches :30
Accuracy: 0.5387931
Processed batches :31
Accuracy: 0.55
Processed batches :32
Accuracy: 0.5564516
Processed batches :33
Accuracy: 0.5625
Processed batches :34
Accuracy: 0.5681818
Processed batches :35
Accuracy: 0.5625
Processed batches :36
Accuracy: 0.55714285
Processed batches :37
Accuracy: 0.5486111
Processed batches :38
Accuracy: 0.5540541
Processed batches :39
Accuracy: 0.5625
Processed batches :40
Accuracy: 0.5673077
Processed batches :41
Accuracy: 0.55625
Processed batches :42
Accuracy: 0.55487806
Processed batches :43
Accuracy: 0.5625
Processed batches :44
Accuracy: 0.56686044
Processed batches :45
Accuracy: 0.57102275
Processed batches :46
Accuracy: 0.5694444
Processed batches :47
Accuracy: 0.57608694


ACCURACY TEST STORY CLOZE TASK EPOCH 1
0.57608694

